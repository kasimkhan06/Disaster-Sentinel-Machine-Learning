{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67e3d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns',None)\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e19f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "049a89ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataFrame Info BEFORE setting DatetimeIndex ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14976 entries, 0 to 14975\n",
      "Data columns (total 23 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   date                  14976 non-null  object \n",
      " 1   prcp(mm/day)          14976 non-null  float64\n",
      " 2   tmax(C)               14976 non-null  float64\n",
      " 3   tmin(C)               14976 non-null  float64\n",
      " 4   tavg(C)               14976 non-null  float64\n",
      " 5   srad_lw(w/m2)         14976 non-null  float64\n",
      " 6   srad_sw(w/m2)         14976 non-null  float64\n",
      " 7   wind_u(m/s)           14976 non-null  float64\n",
      " 8   wind_v(m/s)           14976 non-null  float64\n",
      " 9   wind(m/s)             14976 non-null  float64\n",
      " 10  rel_hum(%)            14976 non-null  float64\n",
      " 11  pet(mm/day)           14610 non-null  float64\n",
      " 12  pet_gleam(mm/day)     14976 non-null  float64\n",
      " 13  aet_gleam(mm/day)     14976 non-null  float64\n",
      " 14  evap_canopy(mm/day)   14976 non-null  float64\n",
      " 15  evap_surface(mm/day)  14976 non-null  float64\n",
      " 16  sm_lvl1(kg/m2)        14976 non-null  float64\n",
      " 17  sm_lvl2(kg/m2)        14976 non-null  float64\n",
      " 18  sm_lvl3(kg/m2)        14976 non-null  float64\n",
      " 19  sm_lvl4(kg/m2)        14976 non-null  float64\n",
      " 20  lstm_streamflow       14976 non-null  float64\n",
      " 21  streamflow_observed   14227 non-null  float64\n",
      " 22  flood_occurred        14976 non-null  int64  \n",
      "dtypes: float64(21), int64(1), object(1)\n",
      "memory usage: 2.6+ MB\n",
      "None\n",
      "\n",
      "--- DataFrame Info AFTER setting DatetimeIndex ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 14976 entries, 1980-01-01 to 2020-12-31\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   prcp(mm/day)          14976 non-null  float64\n",
      " 1   tmax(C)               14976 non-null  float64\n",
      " 2   tmin(C)               14976 non-null  float64\n",
      " 3   tavg(C)               14976 non-null  float64\n",
      " 4   srad_lw(w/m2)         14976 non-null  float64\n",
      " 5   srad_sw(w/m2)         14976 non-null  float64\n",
      " 6   wind_u(m/s)           14976 non-null  float64\n",
      " 7   wind_v(m/s)           14976 non-null  float64\n",
      " 8   wind(m/s)             14976 non-null  float64\n",
      " 9   rel_hum(%)            14976 non-null  float64\n",
      " 10  pet(mm/day)           14610 non-null  float64\n",
      " 11  pet_gleam(mm/day)     14976 non-null  float64\n",
      " 12  aet_gleam(mm/day)     14976 non-null  float64\n",
      " 13  evap_canopy(mm/day)   14976 non-null  float64\n",
      " 14  evap_surface(mm/day)  14976 non-null  float64\n",
      " 15  sm_lvl1(kg/m2)        14976 non-null  float64\n",
      " 16  sm_lvl2(kg/m2)        14976 non-null  float64\n",
      " 17  sm_lvl3(kg/m2)        14976 non-null  float64\n",
      " 18  sm_lvl4(kg/m2)        14976 non-null  float64\n",
      " 19  lstm_streamflow       14976 non-null  float64\n",
      " 20  streamflow_observed   14227 non-null  float64\n",
      " 21  flood_occurred        14976 non-null  int64  \n",
      "dtypes: float64(21), int64(1)\n",
      "memory usage: 2.6 MB\n",
      "None\n",
      "\n",
      "--- DataFrame Head AFTER setting DatetimeIndex ---\n",
      "            prcp(mm/day)  tmax(C)  tmin(C)  tavg(C)  srad_lw(w/m2)  \\\n",
      "date                                                                 \n",
      "1980-01-01           0.0    28.11    14.04    21.08         335.40   \n",
      "1980-01-02           0.0    28.33    13.94    21.14         345.16   \n",
      "1980-01-03           0.0    28.16    14.35    21.26         349.14   \n",
      "1980-01-04           0.0    28.33    14.83    21.58         353.16   \n",
      "1980-01-05           0.0    28.05    14.73    21.39         348.57   \n",
      "\n",
      "            srad_sw(w/m2)  wind_u(m/s)  wind_v(m/s)  wind(m/s)  rel_hum(%)  \\\n",
      "date                                                                         \n",
      "1980-01-01         308.97         0.51        -0.20       0.55       57.89   \n",
      "1980-01-02         303.75         0.42         0.48       0.64       60.80   \n",
      "1980-01-03         300.51         0.63         0.29       0.69       61.53   \n",
      "1980-01-04         299.13        -1.65         0.79       1.83       55.99   \n",
      "1980-01-05         305.00        -1.61         0.74       1.77       52.61   \n",
      "\n",
      "            pet(mm/day)  pet_gleam(mm/day)  aet_gleam(mm/day)  \\\n",
      "date                                                            \n",
      "1980-01-01          NaN               2.85               2.03   \n",
      "1980-01-02          NaN               2.90               2.07   \n",
      "1980-01-03          NaN               2.76               1.89   \n",
      "1980-01-04          NaN               2.71               1.81   \n",
      "1980-01-05          NaN               2.88               1.92   \n",
      "\n",
      "            evap_canopy(mm/day)  evap_surface(mm/day)  sm_lvl1(kg/m2)  \\\n",
      "date                                                                    \n",
      "1980-01-01                  0.0                  0.79            6.93   \n",
      "1980-01-02                  0.0                  0.75            6.74   \n",
      "1980-01-03                  0.0                  0.70            6.56   \n",
      "1980-01-04                  0.0                  0.73            6.39   \n",
      "1980-01-05                  0.0                  0.73            6.23   \n",
      "\n",
      "            sm_lvl2(kg/m2)  sm_lvl3(kg/m2)  sm_lvl4(kg/m2)  lstm_streamflow  \\\n",
      "date                                                                          \n",
      "1980-01-01           66.29          153.43          511.52           73.769   \n",
      "1980-01-02           66.07          153.25          511.37           98.157   \n",
      "1980-01-03           65.85          153.09          511.23          121.992   \n",
      "1980-01-04           65.64          152.91          511.09          133.136   \n",
      "1980-01-05           65.42          152.74          510.95          133.301   \n",
      "\n",
      "            streamflow_observed  flood_occurred  \n",
      "date                                             \n",
      "1980-01-01                111.1               0  \n",
      "1980-01-02                113.4               0  \n",
      "1980-01-03                104.3               0  \n",
      "1980-01-04                104.1               0  \n",
      "1980-01-05                103.7               0  \n",
      "\n",
      "--- Missing values BEFORE imputation (after index fix) ---\n",
      "pet(mm/day)            366\n",
      "streamflow_observed    749\n",
      "dtype: int64\n",
      "\n",
      "--- Missing values AFTER imputation ---\n",
      "pet(mm/day)            0\n",
      "streamflow_observed    0\n",
      "dtype: int64\n",
      "\n",
      "--- Final Dataset Info After All Preprocessing ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 14976 entries, 1980-01-01 to 2020-12-31\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   prcp(mm/day)          14976 non-null  float64\n",
      " 1   tmax(C)               14976 non-null  float64\n",
      " 2   tmin(C)               14976 non-null  float64\n",
      " 3   tavg(C)               14976 non-null  float64\n",
      " 4   srad_lw(w/m2)         14976 non-null  float64\n",
      " 5   srad_sw(w/m2)         14976 non-null  float64\n",
      " 6   wind_u(m/s)           14976 non-null  float64\n",
      " 7   wind_v(m/s)           14976 non-null  float64\n",
      " 8   wind(m/s)             14976 non-null  float64\n",
      " 9   rel_hum(%)            14976 non-null  float64\n",
      " 10  pet(mm/day)           14976 non-null  float64\n",
      " 11  pet_gleam(mm/day)     14976 non-null  float64\n",
      " 12  aet_gleam(mm/day)     14976 non-null  float64\n",
      " 13  evap_canopy(mm/day)   14976 non-null  float64\n",
      " 14  evap_surface(mm/day)  14976 non-null  float64\n",
      " 15  sm_lvl1(kg/m2)        14976 non-null  float64\n",
      " 16  sm_lvl2(kg/m2)        14976 non-null  float64\n",
      " 17  sm_lvl3(kg/m2)        14976 non-null  float64\n",
      " 18  sm_lvl4(kg/m2)        14976 non-null  float64\n",
      " 19  lstm_streamflow       14976 non-null  float64\n",
      " 20  streamflow_observed   14976 non-null  float64\n",
      " 21  flood_occurred        14976 non-null  int64  \n",
      "dtypes: float64(21), int64(1)\n",
      "memory usage: 2.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # Ensure numpy is imported for numerical operations\n",
    "import matplotlib.pyplot as plt # For plotting\n",
    "import seaborn as sns # For plotting style\n",
    "\n",
    "# Assume 'df' is your current DataFrame as per the latest info() output\n",
    "\n",
    "# --- Step 1: Convert 'date' column to DatetimeIndex ---\n",
    "print(\"--- DataFrame Info BEFORE setting DatetimeIndex ---\")\n",
    "print(df.info())\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date']) # Convert the 'date' column to datetime objects\n",
    "df = df.set_index('date').sort_index() # Set 'date' as index and sort it chronologically\n",
    "\n",
    "print(\"\\n--- DataFrame Info AFTER setting DatetimeIndex ---\")\n",
    "print(df.info())\n",
    "print(\"\\n--- DataFrame Head AFTER setting DatetimeIndex ---\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# --- Step 2: Handle Missing Values ---\n",
    "cols_with_missing = ['pet(mm/day)', 'streamflow_observed']\n",
    "\n",
    "print(\"\\n--- Missing values BEFORE imputation (after index fix) ---\")\n",
    "print(df[cols_with_missing].isnull().sum())\n",
    "\n",
    "# Apply linear interpolation (fills NaNs between valid observations)\n",
    "for col in cols_with_missing:\n",
    "    df[col] = df[col].interpolate(method='linear')\n",
    "\n",
    "# For 'pet(mm/day)', specifically, apply backward-fill (bfill) to handle NaNs at the beginning\n",
    "# if they were not filled by linear interpolation (e.g., if there are leading NaNs)\n",
    "df['pet(mm/day)'] = df['pet(mm/day)'].bfill()\n",
    "\n",
    "print(\"\\n--- Missing values AFTER imputation ---\")\n",
    "print(df[cols_with_missing].isnull().sum())\n",
    "\n",
    "# Final verification of the dataset\n",
    "print(\"\\n--- Final Dataset Info After All Preprocessing ---\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5ba8782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prcp_lag1'] = df['prcp(mm/day)'].shift(1)\n",
    "df['prcp_cum3'] = df['prcp(mm/day)'].rolling(window=3).sum()\n",
    "df['prcp_cum7'] = df['prcp(mm/day)'].rolling(window=7).sum()\n",
    "df['sm_lvl1_lag1'] = df['sm_lvl1(kg/m2)'].shift(1)\n",
    "df['sm_lvl1_avg3'] = df['sm_lvl1(kg/m2)'].rolling(window=3).mean()\n",
    "df['streamflow_lag1'] = df['streamflow_observed'].shift(1)\n",
    "df['streamflow_avg3'] = df['streamflow_observed'].rolling(window=3).mean()\n",
    "df['doy'] = df.index.dayofyear\n",
    "\n",
    "# Soil Moisture Anomaly\n",
    "monthly_avg = df.groupby(df.index.month)['sm_lvl1(kg/m2)'].transform('mean')\n",
    "df['sm_anomaly'] = df['sm_lvl1(kg/m2)'] - monthly_avg\n",
    "\n",
    "# Drop rows with NaNs due to shifting/rolling\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93352a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'prcp_lag1', 'prcp_cum3', 'prcp_cum7', \n",
    "    'sm_lvl1_lag1', 'sm_lvl1_avg3', \n",
    "    'streamflow_lag1', 'streamflow_avg3', \n",
    "    'doy', 'sm_anomaly'\n",
    "]\n",
    "X = df[features]\n",
    "y = df['flood_occurred']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b36797ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed388c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab795f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(weights='distance')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance', metric='minkowski', p=2)\n",
    "knn.fit(X_train_sm, y_train_sm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bebf0e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97      2627\n",
      "           1       0.69      0.94      0.80       367\n",
      "\n",
      "    accuracy                           0.94      2994\n",
      "   macro avg       0.84      0.94      0.88      2994\n",
      "weighted avg       0.95      0.94      0.94      2994\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2472  155]\n",
      " [  22  345]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ba95350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.7771912845780238\n",
      "Optimized Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      2627\n",
      "           1       0.78      0.87      0.83       367\n",
      "\n",
      "    accuracy                           0.96      2994\n",
      "   macro avg       0.88      0.92      0.90      2994\n",
      "weighted avg       0.96      0.96      0.96      2994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "y_probs = knn.predict_proba(X_test)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "optimal_thresh = thresholds[f1.argmax()]\n",
    "print(\"Optimal Threshold:\", optimal_thresh)\n",
    "\n",
    "# Apply threshold\n",
    "y_thresh = (y_probs >= optimal_thresh).astype(int)\n",
    "print(\"Optimized Classification Report:\\n\", classification_report(y_test, y_thresh))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
